{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "#Preprocesamiento\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS #importar set de stopwords\n",
    "from nltk.stem import SnowballStemmer #importar stemmer\n",
    "nlp = spacy.load('es_core_news_sm') #python -m spacy download es\n",
    "\n",
    "#Bag-of-words\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(doc, sep=None, stopwords_remove =False, lemmatization=False, stemming = False, vocabulary=None):\n",
    "    '''\n",
    "    Por defecto divide la sentencia por el carácter espacio.\n",
    "    Ej: 'Data Mining is the best course'->['Data',  'Mining', 'is', 'the', 'best', 'course']\n",
    "    \n",
    "    Input: \n",
    "    1. doc: str, documento.\n",
    "    2. sep: str, carácter para dividir el documento en tokens, por defecto es el espacio.\n",
    "    3. stopwords_remove: bool, si es True remueve los stopwords del documento.\n",
    "    4. lemmatization: bool, si es True lleva las palabras a su lema.\n",
    "    5. stemming: bool, si es True lleva las palabas a su raíz.\n",
    "    6. vocabuary: list, si un vocabulario es dado filtra las palabras que no estan presentes en el.\n",
    "    \n",
    "    Output: \n",
    "    list, lista de tokens.\n",
    "    \n",
    "    Nota: aplicar stemming y lemmatization al mismo tiempo no es correcto.\n",
    "    '''\n",
    "    doc = re.sub(r'\\S+@\\S+', '', doc) #elimina correos electrónicos  \n",
    "    doc = re.sub(r'[^\\w\\s]','', doc) #elimina los símbolos de puntuación excepto underscore\n",
    "    doc = re.sub(r'[_]', '', doc) #elimina underscore\n",
    "    doc = re.sub(r'[a-zA-Z]+[0-9]+', '', doc) #elimina los tokens que contienen letras y números\n",
    "    doc = re.sub(r'([ø ÿ þ])', ' ', doc) #reemplazas los símbolos contenidos por un espacio \n",
    "    doc = re.sub(r'[0-9]', '', doc) #elimina los tokens númericos\n",
    "    doc = re.sub(r'(ñuñoa)', ' ñuñoa ', doc) #reemplaza ñuñoa por ñuñoa más espacios\n",
    "    doc = re.sub(r'(daños)', ' daños ', doc) #reemplaza daños por daños más espacios\n",
    "    tokens = doc.split(sep) #tokenización\n",
    "    tokens = [word.lower() for word in tokens] #pasar todas las palabras a minúsculas\n",
    "    \n",
    "    \n",
    "    \n",
    "    if stopwords_remove ==True: #remover stopwords y palabras con menos de tres caracteres\n",
    "        tokens = [word for word in tokens if word not in STOP_WORDS and len(word)>2]\n",
    "    \n",
    "    if lemmatization==True:\n",
    "        tokens = [nlp(word)[0].lemma_ for word in tokens]\n",
    "        \n",
    "    if stemming == True:\n",
    "        stemmer = SnowballStemmer('spanish')\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    if vocabulary is not None:\n",
    "        tokens = [word for word in tokens if word in vocabulary]\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"stopwords_remove\": False, 'stemming': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos objetos para llevar el corpus a bag-of-words\n",
    "tf_vectorizer = CountVectorizer(analyzer='word', tokenizer=lambda text: tokenizer(text, **args))\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', tokenizer=lambda text: tokenizer(text, **args)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sin_fecha_siniestro</th>\n",
       "      <th>sin_relato</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_prose</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33474</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>Por medio  de la presente  comunicamos  a uds....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32730</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>ESTABA ESTACIONADO EL LA CALLE ROTEMBURGO ENTR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33469</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>Estacionado  al volver no encontre el vehiculo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33466</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>El abuelo de mi polola  salio del domicilio y ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32220</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>ESTANDO ESTACIONADO VEHICULO EN AVDA PACIFICO ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sin_fecha_siniestro  \\\n",
       "id_prose                       \n",
       "33474             2011-01-01   \n",
       "32730             2011-01-01   \n",
       "33469             2011-01-01   \n",
       "33466             2011-01-01   \n",
       "32220             2011-01-01   \n",
       "\n",
       "                                                 sin_relato  \n",
       "id_prose                                                     \n",
       "33474     Por medio  de la presente  comunicamos  a uds....  \n",
       "32730     ESTABA ESTACIONADO EL LA CALLE ROTEMBURGO ENTR...  \n",
       "33469     Estacionado  al volver no encontre el vehiculo...  \n",
       "33466     El abuelo de mi polola  salio del domicilio y ...  \n",
       "32220     ESTANDO ESTACIONADO VEHICULO EN AVDA PACIFICO ...  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importar la base de datos\n",
    "df = pd.read_pickle('../data/robos_prose_v1.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function <lambda> at 0x0000026A02A6B6A8>,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extraer vocabulario\n",
    "tf_vectorizer.fit(df['sin_relato'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>por</td>\n",
       "      <td>33913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medio</td>\n",
       "      <td>28291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>12106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la</td>\n",
       "      <td>25266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>presente</td>\n",
       "      <td>34442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vocabulary  frequency\n",
       "0        por      33913\n",
       "1      medio      28291\n",
       "2         de      12106\n",
       "3         la      25266\n",
       "4   presente      34442"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear dataframe con las frecuencias de las palabras\n",
    "freq_by_word = tf_vectorizer.vocabulary_\n",
    "vocabulary = pd.Series(list(freq_by_word.keys()))\n",
    "frequency = pd.Series(list(freq_by_word.values()))\n",
    "df_freq_by_word = pd.DataFrame({'vocabulary':vocabulary, 'frequency':frequency})\n",
    "df_freq_by_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44859</th>\n",
       "      <td>útiles</td>\n",
       "      <td>46310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11619</th>\n",
       "      <td>único</td>\n",
       "      <td>46309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>única</td>\n",
       "      <td>46308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>últimos</td>\n",
       "      <td>46307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>último</td>\n",
       "      <td>46306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16425</th>\n",
       "      <td>última</td>\n",
       "      <td>46305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34460</th>\n",
       "      <td>ú</td>\n",
       "      <td>46304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>ùltima</td>\n",
       "      <td>46303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26668</th>\n",
       "      <td>óvil</td>\n",
       "      <td>46302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>ósea</td>\n",
       "      <td>46301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37832</th>\n",
       "      <td>ór</td>\n",
       "      <td>46300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28393</th>\n",
       "      <td>ópticos</td>\n",
       "      <td>46299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37769</th>\n",
       "      <td>óptico</td>\n",
       "      <td>46298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24384</th>\n",
       "      <td>ónix</td>\n",
       "      <td>46297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33338</th>\n",
       "      <td>ón</td>\n",
       "      <td>46296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>ó</td>\n",
       "      <td>46295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>ñuñoa</td>\n",
       "      <td>46294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40626</th>\n",
       "      <td>ñuño</td>\n",
       "      <td>46293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17655</th>\n",
       "      <td>ñuz</td>\n",
       "      <td>46292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>ñuble</td>\n",
       "      <td>46291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35619</th>\n",
       "      <td>ñu</td>\n",
       "      <td>46290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41077</th>\n",
       "      <td>ñostapabarro</td>\n",
       "      <td>46289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35821</th>\n",
       "      <td>ños</td>\n",
       "      <td>46288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27282</th>\n",
       "      <td>ñoresorbital</td>\n",
       "      <td>46287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006</th>\n",
       "      <td>ñoa</td>\n",
       "      <td>46286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25654</th>\n",
       "      <td>ño</td>\n",
       "      <td>46285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45255</th>\n",
       "      <td>ñmañana</td>\n",
       "      <td>46284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>ñiñoa</td>\n",
       "      <td>46283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>ñiquen</td>\n",
       "      <td>46282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42051</th>\n",
       "      <td>ñipas</td>\n",
       "      <td>46281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vocabulary  frequency\n",
       "44859        útiles      46310\n",
       "11619         único      46309\n",
       "5145          única      46308\n",
       "26707       últimos      46307\n",
       "6297         último      46306\n",
       "16425        última      46305\n",
       "34460             ú      46304\n",
       "7984         ùltima      46303\n",
       "26668          óvil      46302\n",
       "4214           ósea      46301\n",
       "37832            ór      46300\n",
       "28393       ópticos      46299\n",
       "37769        óptico      46298\n",
       "24384          ónix      46297\n",
       "33338            ón      46296\n",
       "2184              ó      46295\n",
       "1071          ñuñoa      46294\n",
       "40626          ñuño      46293\n",
       "17655           ñuz      46292\n",
       "9562          ñuble      46291\n",
       "35619            ñu      46290\n",
       "41077  ñostapabarro      46289\n",
       "35821           ños      46288\n",
       "27282  ñoresorbital      46287\n",
       "20006           ñoa      46286\n",
       "25654            ño      46285\n",
       "45255       ñmañana      46284\n",
       "2395          ñiñoa      46283\n",
       "6409         ñiquen      46282\n",
       "42051         ñipas      46281"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq_by_word.sort_values('frequency', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26448</th>\n",
       "      <td>abajn</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35204</th>\n",
       "      <td>abajarme</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31236</th>\n",
       "      <td>abajar</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39017</th>\n",
       "      <td>abajao</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27161</th>\n",
       "      <td>abaj</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>abadonado</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18750</th>\n",
       "      <td>abado</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8963</th>\n",
       "      <td>abadia</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32543</th>\n",
       "      <td>abad</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8628</th>\n",
       "      <td>aba</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>ab</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32707</th>\n",
       "      <td>aavisaron</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35133</th>\n",
       "      <td>aautomovil</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40121</th>\n",
       "      <td>aautomotora</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23469</th>\n",
       "      <td>aauto</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32689</th>\n",
       "      <td>aastorgami</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>aasegurado</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21719</th>\n",
       "      <td>aas</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33236</th>\n",
       "      <td>aarmas</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21686</th>\n",
       "      <td>aarmados</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45540</th>\n",
       "      <td>aamenazandome</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15977</th>\n",
       "      <td>aalto</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>aalrma</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8457</th>\n",
       "      <td>aalas</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12677</th>\n",
       "      <td>aal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33060</th>\n",
       "      <td>aacolor</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>aacercan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35611</th>\n",
       "      <td>aabro</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>aa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vocabulary  frequency\n",
       "26448          abajn         29\n",
       "35204       abajarme         28\n",
       "31236         abajar         27\n",
       "39017         abajao         26\n",
       "27161           abaj         25\n",
       "9105       abadonado         24\n",
       "18750          abado         23\n",
       "8963          abadia         22\n",
       "32543           abad         21\n",
       "8628             aba         20\n",
       "4108              ab         19\n",
       "32707      aavisaron         18\n",
       "35133     aautomovil         17\n",
       "40121    aautomotora         16\n",
       "23469          aauto         15\n",
       "32689     aastorgami         14\n",
       "6265      aasegurado         13\n",
       "21719            aas         12\n",
       "33236         aarmas         11\n",
       "21686       aarmados         10\n",
       "45540  aamenazandome          9\n",
       "15977          aalto          8\n",
       "5899          aalrma          7\n",
       "8457           aalas          6\n",
       "12677            aal          5\n",
       "33060        aacolor          4\n",
       "1354        aacercan          3\n",
       "35611          aabro          2\n",
       "5076              aa          1\n",
       "6                  a          0"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq_by_word.sort_values('frequency', ascending=False).tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementos extras a procesar:\n",
    "\n",
    "1. Carácteres a extraer: [ø, ÿ, þ]\n",
    "2. normalizar (stemming, lemmatization): [óptipcos, óptico]\n",
    "3. Eliminar tíldes.\n",
    "4. Split: [ñuñoa, daños]\n",
    "5. vehiculo: [veh., vh, vehículo, vehiculo]\n",
    "\n",
    "- Carácteres a homologar: [(ç, d)]\n",
    "- stopwords\n",
    "- corrección ortográfica usando embedding (útil para leves pifias, 60 ms).\n",
    "- el otro corrector ortográfico tarda 230 ms.\n",
    "- lemmatizador spacy -> 5 ms, lemmatizador CREA -> 137 ns, no funcinan con faltas ortográficas.\n",
    "- ver que carácteres están cortando las palabras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
